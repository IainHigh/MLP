{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Dataframes\n",
    "import re  # Regular expressions \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  # Split text into words\n",
    "from nltk.corpus import stopwords  # Lists of unimportant words\n",
    "from collections import Counter, defaultdict  # Count word frequency & provide more versatile dicts\n",
    "from pandas.core.common import flatten  # Collapse lists of lists\n",
    "from nltk.stem.wordnet import WordNetLemmatizer  # Reduce terms to their root\n",
    "from nltk import pos_tag  # Tag words with parts of speech\n",
    "import seaborn as sns  # Visualisations\n",
    "import matplotlib.pyplot as plt  # Visualisations\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text to TF-IDF representations\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Check similarities between vectors\n",
    "from textwrap import wrap  # format long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment out the following lines if you haven't downloaded the NLTK packages (you only need to do this once)\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe by reading the goodreads_books.csv file\n",
    "books = pd.read_csv('goodreads_books.csv')\n",
    "\n",
    "# Remove non-English books\n",
    "books = books[books['language_code'] == 'eng']\n",
    "\n",
    "# Remove books without a description or \"\" in the description\n",
    "books = books[books['description'].notnull()]\n",
    "books = books[books['description'] != '\"\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = books['description']\n",
    "descriptions = descriptions.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map tags to ones that the lemmatizer will understand.\n",
    "tag_map = defaultdict(lambda: \"n\")  # by default, assume nouns\n",
    "tag_map['J'] = \"a\"  # adjectives\n",
    "tag_map['V'] = \"v\"  # verbs\n",
    "tag_map['R'] = \"r\"  # adverbs\n",
    "\n",
    "# Create a lemmatizing object\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Get a list of stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def process_descriptions(tokens):\n",
    "    \"\"\"Process a list of tokens: tag, lemmatize, remove stopwords and short words.\"\"\"\n",
    "    # Tag tokens with pos_tagger and convert each tag for the lemmatizer\n",
    "    tagged_tokens = [(token, tag_map[pos[0]]) for token, pos in pos_tag(tokens)]\n",
    "    \n",
    "    # Lemmatize tokens and filter\n",
    "    lemmatized = [lemma.lemmatize(word, pos) for word, pos in tagged_tokens]\n",
    "    return [word.lower() for word in lemmatized if word.lower() not in stops and len(word) > 2]\n",
    "\n",
    "# Assuming 'descriptions' is a pandas Series of lists of tokens\n",
    "# Apply the processing function to each description\n",
    "# If 'descriptions' contains raw text instead of tokens, tokenize them first\n",
    "processed_descriptions = descriptions.apply(process_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the modified descriptions back into the dataframe\n",
    "books['modified_description'] = descriptions\n",
    "books.head(20)\n",
    "\n",
    "descriptions = books[\"modified_description\"].apply(lambda text: \" \".join(text))\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "books.to_csv('Datasets/goodreads_books_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the tf-idf matrix for each modified description\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=0.01)\n",
    "\n",
    "description_dtm = tfidf_vectorizer.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that processes a text description into the same format as the provided descriptions.\n",
    "\n",
    "def convert_text_to_vector(text):\n",
    "    \"\"\"Converts a text string into a TFIDF vector\n",
    "    \n",
    "       Input:\n",
    "           - text (str): a book description\n",
    "       Output:\n",
    "           - vector (scipy sparse matrix): a tf-idf vector for the description\n",
    "    \"\"\"\n",
    "    # Clean text\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-z ]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # Lemmatize and remove stopwords\n",
    "    text = text.split(\" \")\n",
    "    text = get_wordnet_tags(text)\n",
    "    text = [lemma.lemmatize(word=word[0], pos=word[1]) for word in text]\n",
    "    text = [word for word in text if word not in stops and len(word) > 3]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Convert the description to a TF-IDF vector\n",
    "    vector = tfidf_vectorizer.transform([text])\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179188</th>\n",
       "      <td>The true story as told by a mother and daughte...</td>\n",
       "      <td>0.427919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109371</th>\n",
       "      <td>The daughter of esteemed writer Paula Fox and ...</td>\n",
       "      <td>0.366478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106773</th>\n",
       "      <td>Now Martini delivers Paul Madriani's most chal...</td>\n",
       "      <td>0.353470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448931</th>\n",
       "      <td>Duke Leto Atreides is now the skilful ruler of...</td>\n",
       "      <td>0.342531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292067</th>\n",
       "      <td>Dedicated to mothers, daughters and sons whose...</td>\n",
       "      <td>0.324415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118996</th>\n",
       "      <td>A witty and irresistible story of a mother and...</td>\n",
       "      <td>0.321737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>When Jess's daughter, Anna, is reported lost i...</td>\n",
       "      <td>0.314948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343346</th>\n",
       "      <td>When Jess's daughter, Anna, is reported lost i...</td>\n",
       "      <td>0.314948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264353</th>\n",
       "      <td>After her husband takes a concubine, Madame Li...</td>\n",
       "      <td>0.312969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101648</th>\n",
       "      <td>The first volume of the book series \"Successfu...</td>\n",
       "      <td>0.312871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  similarity\n",
       "179188  The true story as told by a mother and daughte...    0.427919\n",
       "109371  The daughter of esteemed writer Paula Fox and ...    0.366478\n",
       "106773  Now Martini delivers Paul Madriani's most chal...    0.353470\n",
       "448931  Duke Leto Atreides is now the skilful ruler of...    0.342531\n",
       "292067  Dedicated to mothers, daughters and sons whose...    0.324415\n",
       "118996  A witty and irresistible story of a mother and...    0.321737\n",
       "5595    When Jess's daughter, Anna, is reported lost i...    0.314948\n",
       "343346  When Jess's daughter, Anna, is reported lost i...    0.314948\n",
       "264353  After her husband takes a concubine, Madame Li...    0.312969\n",
       "101648  The first volume of the book series \"Successfu...    0.312871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example description string \n",
    "\n",
    "test_description = \"\"\"Brittany K. Barnett was only a law student when she came across the case that would change her life forever—that of Sharanda Jones, single mother, business owner, and, like Brittany, Black daughter of the rural South. A victim of America’s devastating war on drugs, Sharanda had been torn away from her young daughter and was serving a life sentence without parole—for a first-time drug offense. In Sharanda, Brittany saw haunting echoes of her own life, as the daughter of a formerly incarcerated mother. As she studied this case, a system came into focus in which widespread racial injustice forms the core of America’s addiction to incarceration. Moved by Sharanda’s plight, Brittany set to work to gain her freedom.\"\"\"\n",
    "\n",
    "# Convert the test description to a vector \n",
    "\n",
    "query_vector = convert_text_to_vector(test_description)\n",
    "\n",
    "\n",
    "# Use cosine similarity to find the most similar vectors to the test\n",
    "\n",
    "similarities = cosine_similarity(query_vector, description_dtm).flatten()\n",
    "\n",
    "books['similarity'] = similarities\n",
    "\n",
    "# Sort the books by similarity\n",
    "books.sort_values('similarity', ascending=False, inplace=True)\n",
    "\n",
    "# Print the top 10 most similar books\n",
    "books[['title', 'similarity']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "path = \"Datasets/goodreads_interactions.csv\"\n",
    "\n",
    "# Define the chunksize for reading the data\n",
    "chunksize = 10 ** 6\n",
    "\n",
    "# Create a dataframe for user with id 661ff6b7041ea1935101f16846e3cba6 will need to use batch processing\n",
    "\n",
    "# Initialize reader object: reader\n",
    "user_id = '661ff6b7041ea1935101f16846e3cba6'\n",
    "\n",
    "user_df = pd.DataFrame()\n",
    "\n",
    "# Process the file in chunks\n",
    "with pd.read_csv(path, chunksize=chunksize) as reader:\n",
    "    for chunk in reader:\n",
    "        user_df = pd.concat([user_df, chunk[chunk['user_id'] == user_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              isbn language_code  \\\n",
      "316182  0312364121           eng   \n",
      "33541   1624300138           eng   \n",
      "64325   0987526146           eng   \n",
      "231961  1465341889           eng   \n",
      "383650  0525478817           eng   \n",
      "371529  1476753164           eng   \n",
      "196819  1455549002           eng   \n",
      "371680  1476763976           eng   \n",
      "\n",
      "                                              description         isbn13  \\\n",
      "316182  From the author of the smash-hit bestseller Fi...  9780312364120   \n",
      "33541   From the New York Times and USA Today bestsell...  9781624300134   \n",
      "64325   Ryan Kendall is broken. He understands pain. H...  9780987526144   \n",
      "231961  Every action has consequences.\\nWaking in an u...  9781465341884   \n",
      "383650  There is an alternate cover edition \u0001.\\n\"I fel...  9780525478812   \n",
      "371529  From #1 New York Timesbestselling author Colle...  9781476753164   \n",
      "196819  Five months ago, Camryn and Andrew, both deali...  9781455549009   \n",
      "371680  A Chicago reporter in her mid-twenties unexpec...  9781476763972   \n",
      "\n",
      "         book_id                                              title  \\\n",
      "316182   6668467  From the author of the smash-hit bestseller Fi...   \n",
      "33541   18467189  From the New York Times and USA Today bestsell...   \n",
      "64325   18304765  Ryan Kendall is broken. He understands pain. H...   \n",
      "231961  12368985  Every action has consequences.\\nWaking in an u...   \n",
      "383650  11870085  There is an alternate cover edition \u0001.\\n\"I fel...   \n",
      "371529  18143950  From #1 New York Timesbestselling author Colle...   \n",
      "196819  17899696  Five months ago, Camryn and Andrew, both deali...   \n",
      "371680  18280662  A Chicago reporter in her mid-twenties unexpec...   \n",
      "\n",
      "        num_pages                               modified_description  \\\n",
      "316182        394  [from, author, smash-hit, bestseller, firefly,...   \n",
      "33541         320  [from, new, york, times, usa, today, bestselli...   \n",
      "64325         346  [ryan, kendall, break, understand, pain, know,...   \n",
      "231961        368  [every, action, consequence, waking, unfamilia...   \n",
      "383650        313  [there, alternate, cover, edition, fell, love,...   \n",
      "371529        367  [from, new, york, timesbestselling, author, co...   \n",
      "196819        412  [five, month, ago, camryn, andrew, deal, perso...   \n",
      "371680        320  [chicago, reporter, mid-twenties, unexpectedly...   \n",
      "\n",
      "        similarity  \n",
      "316182    0.184981  \n",
      "33541     0.105421  \n",
      "64325     0.035403  \n",
      "231961    0.035221  \n",
      "383650    0.031636  \n",
      "371529    0.025728  \n",
      "196819    0.023872  \n",
      "371680    0.008061  \n"
     ]
    }
   ],
   "source": [
    "# Get the descriptions for the books the user has read\n",
    "user_books = user_df['book_id'].unique()\n",
    "user_books = books[books['book_id'].isin(user_books)]\n",
    "print(user_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056290355227640046\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean similarty between the provided description and the descriptions of the books the user has read\n",
    "mean_similarity = user_books['similarity'].mean()\n",
    "print(mean_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
